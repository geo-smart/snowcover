{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "# Define the CNN architecture\n",
    "class SnowCoverCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SnowCoverCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 output classes (snow, no snow)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load and preprocess the data\n",
    "def load_data(planet_image_path, snow_cover_label_path):\n",
    "    # Load Planet imagery\n",
    "    with rasterio.open(planet_image_path) as src:\n",
    "        planet_image = src.read().astype(np.float32)\n",
    "\n",
    "    # Load snow cover labels\n",
    "    with rasterio.open(snow_cover_label_path) as src:\n",
    "        snow_cover_label = src.read(1)  # Assuming single-band label\n",
    "\n",
    "    # Normalize Planet imagery\n",
    "    planet_image /= 255.0\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    planet_image_tensor = torch.tensor(planet_image).unsqueeze(0)  # Add batch dimension\n",
    "    snow_cover_label_tensor = torch.tensor(snow_cover_label).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    return planet_image_tensor, snow_cover_label_tensor\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader.dataset)}')\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Define paths to data\n",
    "    planet_image_path = 'planet_image.tif'\n",
    "    snow_cover_label_path = 'snow_cover_label.tif'\n",
    "\n",
    "    # Load data\n",
    "    planet_image, snow_cover_label = load_data(planet_image_path, snow_cover_label_path)\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataset = TensorDataset(planet_image, snow_cover_label)\n",
    "    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = SnowCoverCNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "# Define the CNN architecture\n",
    "class SnowCoverCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SnowCoverCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 output classes (snow, no snow)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load and preprocess the data\n",
    "def load_data(planet_image_path, snow_cover_label_path):\n",
    "    # Load Planet imagery\n",
    "    with rasterio.open(planet_image_path) as src:\n",
    "        planet_image = src.read().astype(np.float32)\n",
    "\n",
    "    # Load snow cover labels\n",
    "    with rasterio.open(snow_cover_label_path) as src:\n",
    "        snow_cover_label = src.read(1)  # Assuming single-band label\n",
    "\n",
    "    # Normalize Planet imagery\n",
    "    planet_image /= 255.0\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    planet_image_tensor = torch.tensor(planet_image).unsqueeze(0)  # Add batch dimension\n",
    "    snow_cover_label_tensor = torch.tensor(snow_cover_label).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    return planet_image_tensor, snow_cover_label_tensor\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader.dataset)}')\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Define paths to data\n",
    "    planet_image_path = 'planet_image.tif'\n",
    "    snow_cover_label_path = 'snow_cover_label.tif'\n",
    "\n",
    "    # Load data\n",
    "    planet_image, snow_cover_label = load_data(planet_image_path, snow_cover_label_path)\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataset = TensorDataset(planet_image, snow_cover_label)\n",
    "    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = SnowCoverCNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
